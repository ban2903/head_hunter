{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "from dataloader import TextDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from transformers import BertPreTrainedModel, BertModel\n",
    "from transformers import AutoConfig, AutoTokenizer, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maksk\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (48) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/frame2.csv')[['description_clear', 'salary_from_rate_and_gross_log']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['salary_from_rate_and_gross_log'] = np.exp(df['salary_from_rate_and_gross_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, maxlen, tokenizer): \n",
    "        #Store the contents of the file in a pandas dataframe\n",
    "        self.df = data.reset_index()\n",
    "        #Initialize the tokenizer for the desired transformer model\n",
    "        self.tokenizer = tokenizer\n",
    "        #Maximum length of the tokens list to keep all the sequences of fixed size\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):    \n",
    "        #Select the sentence and label at the specified index in the data frame\n",
    "        excerpt = self.df.loc[index, 'description_clear']\n",
    "        try:\n",
    "            target = self.df.loc[index, 'salary_from_rate_and_gross_log']\n",
    "        except:\n",
    "            target = 0.0\n",
    "        identifier = self.df.loc[index, 'index']\n",
    "        #Preprocess the text to be suitable for the transformer\n",
    "        tokens = self.tokenizer.tokenize(excerpt) \n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]'] \n",
    "        if len(tokens) < self.maxlen:\n",
    "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] \n",
    "        else:\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] \n",
    "        #Obtain the indices of the tokens in the BERT Vocabulary\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens) \n",
    "        input_ids = torch.tensor(input_ids) \n",
    "        #Obtain the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
    "        attention_mask = (input_ids != 0).long()\n",
    "        \n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "        \n",
    "        return input_ids, attention_mask, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertRegresser(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        #The output layer that takes the [CLS] representation and gives an output\n",
    "        self.cls_layer1 = nn.Linear(config.hidden_size,128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.ff1 = nn.Linear(128,128)\n",
    "        self.tanh1 = nn.Tanh()\n",
    "        self.ff2 = nn.Linear(128,1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        #Feed the input to Bert model to obtain contextualized representations\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #Obtain the representations of [CLS] heads\n",
    "        logits = outputs.last_hidden_state[:,0,:]\n",
    "        output = self.cls_layer1(logits)\n",
    "        output = self.relu1(output)\n",
    "        output = self.ff1(output)\n",
    "        output = self.tanh1(output)\n",
    "        output = self.ff2(output)\n",
    "        return output, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, val_loader, epochs, device):\n",
    "    best_acc = 0\n",
    "    print('Start')\n",
    "    for epoch in trange(epochs, desc=\"Epoch\"):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_rmse = 0\n",
    "        for i, (input_ids, attention_mask, target) in enumerate(iterable=train_loader):\n",
    "            optimizer.zero_grad()  \n",
    "            \n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            \n",
    "            output, _ = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            target= torch.unsqueeze(target, dim=1)\n",
    "            loss = criterion(output, target.type_as(output))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_rmse += get_rmse(output, target.type_as(output), criterion=criterion)\n",
    "            if i % 100 == 0:\n",
    "                print(f'Batch:{i}/{len(train_loader)}')\n",
    "        \n",
    "        print(f\"Training loss is {train_loss/len(train_loader)}\\trmse is {train_rmse/len(train_loader)}\")\n",
    "        val_loss, val_rmse = evaluate(model=model, criterion=criterion, dataloader=val_loader, device=device)\n",
    "        print(\"Epoch {} complete! Validation Loss : {}\".format(epoch, val_loss))\n",
    "        print(f\"Epoch {epoch} complete! Validation loss is {val_loss}\\trmse is {val_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    mean_acc, mean_loss, mean_err, count = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, target in (dataloader):\n",
    "            \n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            output, _ = model(input_ids, attention_mask)\n",
    "            target= torch.unsqueeze(target, dim=1)\n",
    "            mean_loss += criterion(output, target.type_as(output)).item()\n",
    "            mean_err += get_rmse(output, target, criterion=criterion)\n",
    "            count += 1\n",
    "            \n",
    "    return mean_loss/count, mean_err/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def get_rmse(output, target, criterion):\n",
    "    with torch.no_grad():\n",
    "        err = torch.sqrt(criterion(target, output))\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    predicted_label = []\n",
    "    actual_label = []\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, target in (dataloader):\n",
    "            \n",
    "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "            output, _ = model(input_ids, attention_mask)\n",
    "                        \n",
    "            predicted_label += output\n",
    "            actual_label += target\n",
    "            \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = train_test_split(df, test_size=0.3, random_state=0)\n",
    "valid_dataset, test_dataset = train_test_split(valid_dataset, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertRegresser: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertRegresser from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertRegresser from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertRegresser were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['cls_layer1.bias', 'cls_layer1.weight', 'ff2.weight', 'ff2.bias', 'ff1.bias', 'ff1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(\"cointegrated/rubert-tiny\", output_hidden_states=True)\n",
    "## Tokenizer loaded from AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n",
    "## Creating the model from the desired transformer model\n",
    "model = BertRegresser.from_pretrained(\"cointegrated/rubert-tiny\", config=config)\n",
    "## GPU or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "## Putting model to device\n",
    "model = model.to(device)\n",
    "## Takes as the input the logits of the positive class and computes the binary cross-entropy \n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.MSELoss()\n",
    "## Optimizer\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DescriptionDataset(data=train_dataset, maxlen=256, tokenizer=tokenizer)\n",
    "valid_set = DescriptionDataset(data=valid_dataset, maxlen=256, tokenizer=tokenizer)\n",
    "test_set = DescriptionDataset(data=test_dataset, maxlen=256, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_set, batch_size=50)\n",
    "valid_loader = DataLoader(dataset=valid_set, batch_size=50)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5631816106.783083\trmse is 74741.2265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   2%|▏         | 1/50 [05:38<4:36:28, 338.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete! Validation Loss : 5596397018.576271\n",
      "Epoch 0 complete! Validation loss is 5596397018.576271\trmse is 74535.5390625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5594965657.087768\trmse is 74493.8203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 2/50 [11:15<4:29:55, 337.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete! Validation Loss : 5559727154.983051\n",
      "Epoch 1 complete! Validation loss is 5559727154.983051\trmse is 74288.875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5558337307.474306\trmse is 74247.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   6%|▌         | 3/50 [16:52<4:24:13, 337.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 complete! Validation Loss : 5523233310.915255\n",
      "Epoch 2 complete! Validation loss is 5523233310.915255\trmse is 74042.5234375\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5521876000.713052\trmse is 74000.890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 4/50 [22:28<4:18:09, 336.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 complete! Validation Loss : 5486901181.288136\n",
      "Epoch 3 complete! Validation loss is 5486901181.288136\trmse is 73796.4921875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5485576063.243293\trmse is 73754.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 5/50 [28:04<4:12:26, 336.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 complete! Validation Loss : 5450730251.389831\n",
      "Epoch 4 complete! Validation loss is 5450730251.389831\trmse is 73550.7578125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5449436878.639381\trmse is 73509.2109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 6/50 [33:54<4:10:13, 341.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 complete! Validation Loss : 5414719771.118644\n",
      "Epoch 5 complete! Validation loss is 5414719771.118644\trmse is 73305.1875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5413458427.692588\trmse is 73263.703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  14%|█▍        | 7/50 [39:39<4:05:22, 342.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 complete! Validation Loss : 5378870204.745763\n",
      "Epoch 6 complete! Validation loss is 5378870204.745763\trmse is 73060.0\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5377641051.736244\trmse is 73018.5234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 8/50 [45:24<4:00:08, 343.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 complete! Validation Loss : 5343182336.0\n",
      "Epoch 7 complete! Validation loss is 5343182336.0\trmse is 72814.9921875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5341984535.050477\trmse is 72773.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 9/50 [51:08<3:54:43, 343.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 complete! Validation Loss : 5307654755.254237\n",
      "Epoch 8 complete! Validation loss is 5307654755.254237\trmse is 72570.328125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5306488068.656662\trmse is 72528.859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 10/50 [56:53<3:49:20, 344.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 complete! Validation Loss : 5272286211.79661\n",
      "Epoch 9 complete! Validation loss is 5272286211.79661\trmse is 72325.90625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5271151765.94452\trmse is 72284.6171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▏       | 11/50 [1:02:38<3:43:50, 344.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 complete! Validation Loss : 5237078784.542373\n",
      "Epoch 10 complete! Validation loss is 5237078784.542373\trmse is 72081.84375\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5235975865.917235\trmse is 72040.4453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 12/50 [1:08:24<3:38:22, 344.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 complete! Validation Loss : 5202031951.18644\n",
      "Epoch 11 complete! Validation loss is 5202031951.18644\trmse is 71837.984375\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5200960575.912687\trmse is 71796.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  26%|██▌       | 13/50 [1:14:10<3:32:46, 345.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 complete! Validation Loss : 5167145101.016949\n",
      "Epoch 12 complete! Validation loss is 5167145101.016949\trmse is 71594.421875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5166105942.963165\trmse is 71553.1484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 14/50 [1:19:46<3:25:22, 342.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 complete! Validation Loss : 5132419905.084745\n",
      "Epoch 13 complete! Validation loss is 5132419905.084745\trmse is 71351.1953125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5131411893.144156\trmse is 71309.953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 15/50 [1:25:31<3:20:14, 343.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 complete! Validation Loss : 5097853935.18644\n",
      "Epoch 14 complete! Validation loss is 5097853935.18644\trmse is 71108.2890625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5096878496.189177\trmse is 71067.046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 16/50 [1:31:08<3:13:27, 341.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 complete! Validation Loss : 5063449684.067797\n",
      "Epoch 15 complete! Validation loss is 5063449684.067797\trmse is 70865.609375\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5062506189.475216\trmse is 70824.40625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  34%|███▍      | 17/50 [1:36:44<3:06:54, 339.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 complete! Validation Loss : 5029206619.118644\n",
      "Epoch 16 complete! Validation loss is 5029206619.118644\trmse is 70623.2890625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 5028294559.490678\trmse is 70582.109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 18/50 [1:42:18<3:00:14, 337.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 complete! Validation Loss : 4995124513.627119\n",
      "Epoch 17 complete! Validation loss is 4995124513.627119\trmse is 70381.2734375\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4994243716.016371\trmse is 70340.078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 19/50 [1:48:05<2:56:02, 340.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 complete! Validation Loss : 4961202044.20339\n",
      "Epoch 18 complete! Validation loss is 4961202044.20339\trmse is 70139.53125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4960353374.646658\trmse is 70098.546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 20/50 [1:53:54<2:51:32, 343.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 complete! Validation Loss : 4927440081.355932\n",
      "Epoch 19 complete! Validation loss is 4927440081.355932\trmse is 69898.109375\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4926623544.345612\trmse is 69857.1171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  42%|████▏     | 21/50 [1:59:43<2:46:41, 344.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 complete! Validation Loss : 4893839947.932203\n",
      "Epoch 20 complete! Validation loss is 4893839947.932203\trmse is 69657.0390625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4893054777.975444\trmse is 69615.9921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 22/50 [2:05:39<2:42:29, 348.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 complete! Validation Loss : 4860399880.135593\n",
      "Epoch 21 complete! Validation loss is 4860399880.135593\trmse is 69416.234375\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4859646590.079127\trmse is 69375.171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  46%|████▌     | 23/50 [2:11:36<2:37:53, 350.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 complete! Validation Loss : 4827120713.220339\n",
      "Epoch 22 complete! Validation loss is 4827120713.220339\trmse is 69175.796875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4826399088.574807\trmse is 69134.7109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 24/50 [2:17:29<2:32:21, 351.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 complete! Validation Loss : 4794001535.457627\n",
      "Epoch 23 complete! Validation loss is 4794001535.457627\trmse is 68935.6953125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4793311698.364711\trmse is 68894.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 25/50 [2:23:28<2:27:26, 353.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 complete! Validation Loss : 4761043105.627119\n",
      "Epoch 24 complete! Validation loss is 4761043105.627119\trmse is 68695.875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4760384715.845385\trmse is 68654.859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 26/50 [2:29:17<2:20:54, 352.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 complete! Validation Loss : 4728244629.694915\n",
      "Epoch 25 complete! Validation loss is 4728244629.694915\trmse is 68456.4140625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4727618384.560255\trmse is 68415.4609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  54%|█████▍    | 27/50 [2:34:59<2:13:53, 349.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 complete! Validation Loss : 4695607719.050847\n",
      "Epoch 26 complete! Validation loss is 4695607719.050847\trmse is 68217.28125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4695013182.515689\trmse is 68176.3984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 28/50 [2:40:38<2:06:54, 346.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 complete! Validation Loss : 4663130762.847458\n",
      "Epoch 27 complete! Validation loss is 4663130762.847458\trmse is 67978.46875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4662567976.163711\trmse is 67937.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  58%|█████▊    | 29/50 [2:46:27<2:01:25, 346.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 complete! Validation Loss : 4630814033.355932\n",
      "Epoch 28 complete! Validation loss is 4630814033.355932\trmse is 67740.0625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4630283733.973624\trmse is 67699.21875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 30/50 [2:52:14<1:55:39, 346.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 complete! Validation Loss : 4598658411.389831\n",
      "Epoch 29 complete! Validation loss is 4598658411.389831\trmse is 67501.9375\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4598159260.69668\trmse is 67461.171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▏   | 31/50 [2:58:06<1:50:20, 348.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 complete! Validation Loss : 4566662627.254237\n",
      "Epoch 30 complete! Validation loss is 4566662627.254237\trmse is 67264.1640625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4566195099.416099\trmse is 67223.46875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 32/50 [3:03:53<1:44:27, 348.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 complete! Validation Loss : 4534826848.542373\n",
      "Epoch 31 complete! Validation loss is 4534826848.542373\trmse is 67026.78125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4534390806.817644\trmse is 66986.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  66%|██████▌   | 33/50 [3:09:40<1:38:31, 347.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 complete! Validation Loss : 4503151656.135593\n",
      "Epoch 32 complete! Validation loss is 4503151656.135593\trmse is 66789.7265625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4502747484.90041\trmse is 66749.0234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  68%|██████▊   | 34/50 [3:15:26<1:32:37, 347.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 complete! Validation Loss : 4471637309.830508\n",
      "Epoch 33 complete! Validation loss is 4471637309.830508\trmse is 66552.9921875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4471264909.096862\trmse is 66512.3828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 35/50 [3:21:12<1:26:44, 346.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 complete! Validation Loss : 4440283375.18644\n",
      "Epoch 34 complete! Validation loss is 4440283375.18644\trmse is 66316.7421875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4439942773.871759\trmse is 66276.1796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  72%|███████▏  | 36/50 [3:26:59<1:20:55, 346.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 complete! Validation Loss : 4409089806.644068\n",
      "Epoch 35 complete! Validation loss is 4409089806.644068\trmse is 66080.8046875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4408780715.190541\trmse is 66040.2421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  74%|███████▍  | 37/50 [3:32:45<1:15:07, 346.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 complete! Validation Loss : 4378056266.305085\n",
      "Epoch 36 complete! Validation loss is 4378056266.305085\trmse is 65845.2265625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4377779352.796726\trmse is 65804.765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  76%|███████▌  | 38/50 [3:38:33<1:09:24, 347.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 complete! Validation Loss : 4347183972.338983\n",
      "Epoch 37 complete! Validation loss is 4347183972.338983\trmse is 65610.0\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4346938947.929059\trmse is 65569.546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  78%|███████▊  | 39/50 [3:44:20<1:03:37, 347.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 complete! Validation Loss : 4316471952.81356\n",
      "Epoch 38 complete! Validation loss is 4316471952.81356\trmse is 65375.17578125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4316259203.841746\trmse is 65334.70703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 40/50 [3:50:07<57:50, 347.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 complete! Validation Loss : 4285921392.2711864\n",
      "Epoch 39 complete! Validation loss is 4285921392.2711864\trmse is 65140.765625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4285739860.6930423\trmse is 65100.3828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  82%|████████▏ | 41/50 [3:55:54<52:02, 346.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 complete! Validation Loss : 4255530748.745763\n",
      "Epoch 40 complete! Validation loss is 4255530748.745763\trmse is 64906.7421875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4255380961.8481126\trmse is 64866.4140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  84%|████████▍ | 42/50 [4:01:43<46:19, 347.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 complete! Validation Loss : 4225300269.559322\n",
      "Epoch 41 complete! Validation loss is 4225300269.559322\trmse is 64673.08203125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4225181860.671214\trmse is 64632.7578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  86%|████████▌ | 43/50 [4:07:43<40:58, 351.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 complete! Validation Loss : 4195230065.898305\n",
      "Epoch 42 complete! Validation loss is 4195230065.898305\trmse is 64439.83203125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4195143611.1978173\trmse is 64399.5703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|████████▊ | 44/50 [4:13:51<35:38, 356.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 complete! Validation Loss : 4165320617.762712\n",
      "Epoch 43 complete! Validation loss is 4165320617.762712\trmse is 64206.984375\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4165266169.3060484\trmse is 64166.73828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 45/50 [4:19:42<29:32, 354.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 complete! Validation Loss : 4135572863.1864405\n",
      "Epoch 44 complete! Validation loss is 4135572863.1864405\trmse is 63974.58203125\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4135549549.3733516\trmse is 63934.2734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  92%|█████████▏| 46/50 [4:25:34<23:35, 353.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 complete! Validation Loss : 4105984576.8135595\n",
      "Epoch 45 complete! Validation loss is 4105984576.8135595\trmse is 63742.546875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4105993788.827649\trmse is 63702.41015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  94%|█████████▍| 47/50 [4:31:22<17:36, 352.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 complete! Validation Loss : 4076557862.779661\n",
      "Epoch 46 complete! Validation loss is 4076557862.779661\trmse is 63510.9375\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4076598621.075034\trmse is 63470.76953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  96%|█████████▌| 48/50 [4:37:14<11:44, 352.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 complete! Validation Loss : 4047291531.3898306\n",
      "Epoch 47 complete! Validation loss is 4047291531.3898306\trmse is 63279.796875\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4047363556.8749433\trmse is 63239.71875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  98%|█████████▊| 49/50 [4:43:13<05:54, 354.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 complete! Validation Loss : 4018185019.9322033\n",
      "Epoch 48 complete! Validation loss is 4018185019.9322033\trmse is 63048.9765625\n",
      "Batch:0/2199\n",
      "Batch:100/2199\n",
      "Batch:200/2199\n",
      "Batch:300/2199\n",
      "Batch:400/2199\n",
      "Batch:500/2199\n",
      "Batch:600/2199\n",
      "Batch:700/2199\n",
      "Batch:800/2199\n",
      "Batch:900/2199\n",
      "Batch:1000/2199\n",
      "Batch:1100/2199\n",
      "Batch:1200/2199\n",
      "Batch:1300/2199\n",
      "Batch:1400/2199\n",
      "Batch:1500/2199\n",
      "Batch:1600/2199\n",
      "Batch:1700/2199\n",
      "Batch:1800/2199\n",
      "Batch:1900/2199\n",
      "Batch:2000/2199\n",
      "Batch:2100/2199\n",
      "Training loss is 4018288796.5220556\trmse is 63008.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 50/50 [4:49:18<00:00, 347.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 complete! Validation Loss : 3989239307.118644\n",
      "Epoch 49 complete! Validation loss is 3989239307.118644\trmse is 62818.6796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model=model, \n",
    "      criterion=criterion,\n",
    "      optimizer=optimizer, \n",
    "      train_loader=train_loader,\n",
    "      val_loader=valid_loader,\n",
    "      epochs = 50,\n",
    "     device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'regression_model/third.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertRegresser: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertRegresser from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertRegresser from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertRegresser were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['ff2.bias', 'ff2.weight', 'cls_layer1.weight', 'ff1.weight', 'cls_layer1.bias', 'ff1.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = BertRegresser.from_pretrained(\"cointegrated/rubert-tiny\", config=config)\n",
    "bert.load_state_dict(torch.load('regression_model/third.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][1].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, z = model(train_set[0][0].to(device).unsqueeze(0), train_set[0][1].to(device).unsqueeze(0))\n",
    "# for input_ids, attention_mask, target in (dataloader):\n",
    "            \n",
    "#             input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
    "#             output = model(input_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0165, -0.5941,  0.8446, -1.0152, -1.1903,  0.8911, -1.0150,  0.6692,\n",
       "        -0.0823,  1.0956,  1.3675, -0.9616, -0.6173,  1.1120,  0.2065,  0.7564,\n",
       "         0.0050, -0.9943, -0.8755, -1.4005, -0.9810,  0.7830, -1.1040, -0.6733,\n",
       "         1.1221, -0.4395,  1.2176,  0.8622,  1.1510,  0.9769, -0.9694,  1.0767,\n",
       "        -0.6339,  0.9127, -0.0927, -0.8705,  0.8907, -1.0492,  1.1331, -0.2640,\n",
       "        -1.3647,  0.4010,  1.4742, -1.0280, -0.9186,  0.5417, -0.6405,  0.9277,\n",
       "        -1.1187, -1.3352,  1.1012, -1.1103,  0.9032,  0.9564, -1.3408,  1.0993,\n",
       "         1.1243,  0.9001, -1.2059, -0.8907,  1.1102,  0.9942,  0.8966, -0.7747,\n",
       "         1.0933,  1.4284, -1.1696, -0.8015,  0.7859, -0.9075, -1.1437, -0.9550,\n",
       "        -1.3351, -0.9288,  0.9722,  1.1186,  1.0152,  0.4491,  1.1752, -0.5556,\n",
       "         1.1111, -0.8800, -1.0476, -0.6195,  0.7390,  0.8985, -1.0188, -0.8994,\n",
       "        -0.0845, -0.9677, -0.9305, -1.1115,  1.7626,  1.0709,  1.0571,  0.6062,\n",
       "         1.2125,  1.1210, -1.0072,  1.0689, -0.9506, -1.0802,  1.0003, -0.9818,\n",
       "        -1.0225,  0.9788, -0.5020,  0.9160,  0.8743,  0.0688, -0.7903, -0.9603,\n",
       "        -0.7078,  1.1010,  0.9995,  1.1686, -1.1168,  0.8039, -1.2557, -1.0691,\n",
       "        -0.9112, -0.9991, -0.8522, -0.8298,  1.0229, -1.0491, -1.2627,  1.3001,\n",
       "         0.8990,  1.0900, -0.8722, -1.0476, -1.0569,  0.9463,  1.0900,  0.9632,\n",
       "         0.6434, -0.9009,  1.2371, -0.9489, -1.0095,  1.0327,  1.1621, -1.1420,\n",
       "        -0.7337, -1.3594,  1.0154, -1.0230,  1.0681, -0.9613,  1.0669,  0.6065,\n",
       "         0.9792,  0.9599, -0.9960,  0.1260, -1.2081, -0.9328,  1.1628, -1.1077,\n",
       "        -0.9673, -1.3189,  1.1587,  0.8882,  1.1160,  0.9399, -0.9674,  1.0648,\n",
       "        -0.8828,  1.0922, -1.0195, -1.1507, -1.0447,  0.8614, -1.1005,  0.7720,\n",
       "         0.9776,  1.1572, -1.0450,  0.8272,  1.0914,  1.0015,  0.6590,  0.9459,\n",
       "         1.0222, -0.7108, -1.0119, -0.8308,  0.8980, -0.8215,  0.9878, -0.8163,\n",
       "         1.4177, -0.8473,  1.1575,  0.7852,  1.0471, -0.4723, -0.6505, -1.1772,\n",
       "        -0.9651, -1.1254, -1.2006, -0.1199,  1.1663,  1.0026,  0.9171, -0.8973,\n",
       "        -0.4312,  0.9149, -0.9970,  0.7242,  1.0104, -1.3363,  0.9889,  1.2636,\n",
       "         0.9549, -0.7998,  0.5987,  0.9336,  0.8542,  1.1885,  1.0416, -1.0864,\n",
       "         0.8850,  1.1141, -0.8448, -0.6676,  1.1600, -0.4746, -0.9705, -1.2771,\n",
       "         1.0686, -0.6702, -0.7212,  1.1027,  1.1731, -1.0150, -1.0342, -0.9606,\n",
       "         1.0073,  0.8717,  0.9028, -1.0351, -0.9733, -0.8917, -0.8381, -0.8237,\n",
       "         1.0938,  0.5457,  1.0984,  0.9421, -1.3361,  0.7138, -1.3452, -0.9882,\n",
       "        -1.1658, -0.9368,  0.7385,  1.1648, -0.7634,  0.8430, -1.0040, -1.0032,\n",
       "         1.0550, -0.8890, -1.0378,  1.0576,  1.3165, -0.0041,  0.9566,  1.3123,\n",
       "         1.2332,  1.2659, -0.6493,  0.9846, -0.8010, -1.1098, -0.7754, -1.1334,\n",
       "         1.2330, -1.1000, -1.0132,  0.3530,  1.1957,  0.9495, -1.0772,  1.1708,\n",
       "         0.3661,  0.9933,  0.9147, -0.8766, -0.9014, -0.8142, -1.1964,  1.2548,\n",
       "        -1.2147, -1.0283, -1.1620, -1.0814,  0.8944, -1.0752, -0.7565,  1.3051,\n",
       "         1.0235, -0.9577, -0.6061,  0.9555, -1.1001, -1.1726, -0.2333, -1.1493],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z['last_hidden_state'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.cuda()\n",
    "bert.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output, z = bert(train_set[0][0].to(device).unsqueeze(0), train_set[0][1].to(device).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0165, -0.5941,  0.8446, -1.0152, -1.1903,  0.8911, -1.0150,  0.6692,\n",
       "        -0.0823,  1.0956,  1.3675, -0.9616, -0.6173,  1.1120,  0.2065,  0.7564,\n",
       "         0.0050, -0.9943, -0.8755, -1.4005, -0.9810,  0.7830, -1.1040, -0.6733,\n",
       "         1.1221, -0.4395,  1.2176,  0.8622,  1.1510,  0.9769, -0.9694,  1.0767,\n",
       "        -0.6339,  0.9127, -0.0927, -0.8705,  0.8907, -1.0492,  1.1331, -0.2640,\n",
       "        -1.3647,  0.4010,  1.4742, -1.0280, -0.9186,  0.5417, -0.6405,  0.9277,\n",
       "        -1.1187, -1.3352,  1.1012, -1.1103,  0.9032,  0.9564, -1.3408,  1.0993,\n",
       "         1.1243,  0.9001, -1.2059, -0.8907,  1.1102,  0.9942,  0.8966, -0.7747,\n",
       "         1.0933,  1.4284, -1.1696, -0.8015,  0.7859, -0.9075, -1.1437, -0.9550,\n",
       "        -1.3351, -0.9288,  0.9722,  1.1186,  1.0152,  0.4491,  1.1752, -0.5556,\n",
       "         1.1111, -0.8800, -1.0476, -0.6195,  0.7390,  0.8985, -1.0188, -0.8994,\n",
       "        -0.0845, -0.9677, -0.9305, -1.1115,  1.7626,  1.0709,  1.0571,  0.6062,\n",
       "         1.2125,  1.1210, -1.0072,  1.0689, -0.9506, -1.0802,  1.0003, -0.9818,\n",
       "        -1.0225,  0.9788, -0.5020,  0.9160,  0.8743,  0.0688, -0.7903, -0.9603,\n",
       "        -0.7078,  1.1010,  0.9995,  1.1686, -1.1168,  0.8039, -1.2557, -1.0691,\n",
       "        -0.9112, -0.9991, -0.8522, -0.8298,  1.0229, -1.0491, -1.2627,  1.3001,\n",
       "         0.8990,  1.0900, -0.8722, -1.0476, -1.0569,  0.9463,  1.0900,  0.9632,\n",
       "         0.6434, -0.9009,  1.2371, -0.9489, -1.0095,  1.0327,  1.1621, -1.1420,\n",
       "        -0.7337, -1.3594,  1.0154, -1.0230,  1.0681, -0.9613,  1.0669,  0.6065,\n",
       "         0.9792,  0.9599, -0.9960,  0.1260, -1.2081, -0.9328,  1.1628, -1.1077,\n",
       "        -0.9673, -1.3189,  1.1587,  0.8882,  1.1160,  0.9399, -0.9674,  1.0648,\n",
       "        -0.8828,  1.0922, -1.0195, -1.1507, -1.0447,  0.8614, -1.1005,  0.7720,\n",
       "         0.9776,  1.1572, -1.0450,  0.8272,  1.0914,  1.0015,  0.6590,  0.9459,\n",
       "         1.0222, -0.7108, -1.0119, -0.8308,  0.8980, -0.8215,  0.9878, -0.8163,\n",
       "         1.4177, -0.8473,  1.1575,  0.7852,  1.0471, -0.4723, -0.6505, -1.1772,\n",
       "        -0.9651, -1.1254, -1.2006, -0.1199,  1.1663,  1.0026,  0.9171, -0.8973,\n",
       "        -0.4312,  0.9149, -0.9970,  0.7242,  1.0104, -1.3363,  0.9889,  1.2636,\n",
       "         0.9549, -0.7998,  0.5987,  0.9336,  0.8542,  1.1885,  1.0416, -1.0864,\n",
       "         0.8850,  1.1141, -0.8448, -0.6676,  1.1600, -0.4746, -0.9705, -1.2771,\n",
       "         1.0686, -0.6702, -0.7212,  1.1027,  1.1731, -1.0150, -1.0342, -0.9606,\n",
       "         1.0073,  0.8717,  0.9028, -1.0351, -0.9733, -0.8917, -0.8381, -0.8237,\n",
       "         1.0938,  0.5457,  1.0984,  0.9421, -1.3361,  0.7138, -1.3452, -0.9882,\n",
       "        -1.1658, -0.9368,  0.7385,  1.1648, -0.7634,  0.8430, -1.0040, -1.0032,\n",
       "         1.0550, -0.8890, -1.0378,  1.0576,  1.3165, -0.0041,  0.9566,  1.3123,\n",
       "         1.2332,  1.2659, -0.6493,  0.9846, -0.8010, -1.1098, -0.7754, -1.1334,\n",
       "         1.2330, -1.1000, -1.0132,  0.3530,  1.1957,  0.9495, -1.0772,  1.1708,\n",
       "         0.3661,  0.9933,  0.9147, -0.8766, -0.9014, -0.8142, -1.1964,  1.2548,\n",
       "        -1.2147, -1.0283, -1.1620, -1.0814,  0.8944, -1.0752, -0.7565,  1.3051,\n",
       "         1.0235, -0.9577, -0.6061,  0.9555, -1.1001, -1.1726, -0.2333, -1.1493],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z['last_hidden_state'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'regression_model/second.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'regression_model/checkpoint-22000'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f6cd268f7042>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'regression_model/checkpoint-22000'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\maksk\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maksk\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maksk\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'regression_model/checkpoint-22000'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_new = torch.load('regression_model/second.pth', map_location='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, z = model(train_set[0][0].to(device).unsqueeze(0), train_set[0][1].to(device).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8466.5273]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model_new = AutoModelForSequenceClassification.from_pretrained('regression_model/checkpoint-20900/', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avito",
   "language": "python",
   "name": "avito"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
