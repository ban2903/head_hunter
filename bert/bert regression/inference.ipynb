{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "# from metric import compute_metrics_for_regression\n",
    "from dataloader import TextDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    logits = logits[0]\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/frame2.csv')[['description_clear', 'salary_from_rate_and_gross_log']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['salary_from_rate_and_gross_log'] = np.exp(df['salary_from_rate_and_gross_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = train_test_split(df, test_size=0.3, random_state=0)\n",
    "valid_dataset, test_dataset = train_test_split(valid_dataset, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "ds = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_dict({'label': train_dataset['salary_from_rate_and_gross_log'], 'text': train_dataset['description_clear']}),\n",
    "        \"valid\": Dataset.from_dict({'label': valid_dataset['salary_from_rate_and_gross_log'], 'text': valid_dataset['description_clear']}),\n",
    "        \"test\": Dataset.from_dict({'label': test_dataset['salary_from_rate_and_gross_log'], 'text': test_dataset['description_clear']}),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    label = examples['label']\n",
    "    examples = tokenizer(\n",
    "                            examples['text'],\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=MAX_LENGTH,\n",
    "                            return_token_type_ids=False,\n",
    "                            truncation=True,\n",
    "                            padding='max_length',\n",
    "                            return_attention_mask=False,\n",
    "                            return_tensors='pt',\n",
    "    )\n",
    "    examples[\"label\"] = label\n",
    "    return examples\n",
    "\n",
    "for split in ds:\n",
    "    ds[split] = ds[split].map(preprocess_function, remove_columns=[\"label\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maksk\\Anaconda3\\lib\\site-packages\\datasets\\dataset_dict.py:1241: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "# ds.save_to_disk(\"./dataset\")\n",
    "ds = load_from_disk(\"./dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 45199.999999999956,\n",
       " 'input_ids': [[2,\n",
       "   105,\n",
       "   815,\n",
       "   15976,\n",
       "   1439,\n",
       "   324,\n",
       "   25313,\n",
       "   16687,\n",
       "   656,\n",
       "   23939,\n",
       "   751,\n",
       "   117,\n",
       "   2389,\n",
       "   322,\n",
       "   3098,\n",
       "   27095,\n",
       "   626,\n",
       "   312,\n",
       "   19387,\n",
       "   17947,\n",
       "   6253,\n",
       "   7332,\n",
       "   3995,\n",
       "   2182,\n",
       "   23881,\n",
       "   705,\n",
       "   778,\n",
       "   1172,\n",
       "   4144,\n",
       "   13158,\n",
       "   25415,\n",
       "   25696,\n",
       "   1229,\n",
       "   320,\n",
       "   25067,\n",
       "   14889,\n",
       "   20046,\n",
       "   324,\n",
       "   25313,\n",
       "   1229,\n",
       "   23498,\n",
       "   13305,\n",
       "   778,\n",
       "   314,\n",
       "   10138,\n",
       "   18765,\n",
       "   22638,\n",
       "   324,\n",
       "   25313,\n",
       "   17947,\n",
       "   15164,\n",
       "   23423,\n",
       "   342,\n",
       "   2698,\n",
       "   721,\n",
       "   11521,\n",
       "   28377,\n",
       "   2253,\n",
       "   15480,\n",
       "   776,\n",
       "   28194,\n",
       "   2225,\n",
       "   12384,\n",
       "   6455,\n",
       "   11521,\n",
       "   3789,\n",
       "   2454,\n",
       "   21496,\n",
       "   28618,\n",
       "   11521,\n",
       "   2389,\n",
       "   2179,\n",
       "   15687,\n",
       "   1241,\n",
       "   320,\n",
       "   4154,\n",
       "   644,\n",
       "   9611,\n",
       "   25415,\n",
       "   26150,\n",
       "   7274,\n",
       "   22079,\n",
       "   1276,\n",
       "   3995,\n",
       "   4452,\n",
       "   2371,\n",
       "   317,\n",
       "   3881,\n",
       "   1023,\n",
       "   987,\n",
       "   7405,\n",
       "   21010,\n",
       "   866,\n",
       "   5677,\n",
       "   20534,\n",
       "   26629,\n",
       "   21431,\n",
       "   18603,\n",
       "   22793,\n",
       "   24495,\n",
       "   22860,\n",
       "   23498,\n",
       "   18754,\n",
       "   11521,\n",
       "   314,\n",
       "   705,\n",
       "   18318,\n",
       "   626,\n",
       "   15371,\n",
       "   549,\n",
       "   4108,\n",
       "   9401,\n",
       "   12206,\n",
       "   14412,\n",
       "   324,\n",
       "   1813,\n",
       "   4171,\n",
       "   14675,\n",
       "   14776,\n",
       "   887,\n",
       "   23160,\n",
       "   549,\n",
       "   332,\n",
       "   4209,\n",
       "   865,\n",
       "   24550,\n",
       "   8074,\n",
       "   3]]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"regression_model\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=50,\n",
    "    num_train_epochs=20,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.01,\n",
    "    # prediction_loss_only=True,\n",
    "    # use_legacy_prediction_loop=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        inputs['input_ids'] = inputs['input_ids'].squeeze()\n",
    "        outputs = model(inputs['input_ids'])\n",
    "        logits = outputs[0][:, 0]\n",
    "        loss = torch.nn.functional.mse_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maksk\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 109936\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 100\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 100\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22000\n",
      "  2%|▏         | 502/22000 [00:47<35:46, 10.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5631750176.768, 'learning_rate': 1.9545454545454546e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1001/22000 [01:33<32:08, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5656811143.168, 'learning_rate': 1.9090909090909094e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1100/22000 [01:43<31:29, 11.06it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                    \n",
      "  5%|▌         | 1100/22000 [01:49<31:29, 11.06it/s]Saving model checkpoint to regression_model\\checkpoint-1100\n",
      "Configuration saved in regression_model\\checkpoint-1100\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-1100\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5634851840.0, 'eval_runtime': 6.5495, 'eval_samples_per_second': 3596.937, 'eval_steps_per_second': 72.067, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-2199] due to args.save_total_limit\n",
      "  7%|▋         | 1501/22000 [02:27<30:34, 11.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5663838699.52, 'learning_rate': 1.8636363636363638e-05, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 2002/22000 [03:12<30:06, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5635193700.352, 'learning_rate': 1.8181818181818182e-05, 'epoch': 1.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2199/22000 [03:30<29:03, 11.35it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                    \n",
      " 10%|█         | 2200/22000 [03:37<29:03, 11.35it/s]Saving model checkpoint to regression_model\\checkpoint-2200\n",
      "Configuration saved in regression_model\\checkpoint-2200\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-2200\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5634003968.0, 'eval_runtime': 6.4614, 'eval_samples_per_second': 3645.936, 'eval_steps_per_second': 73.049, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-4398] due to args.save_total_limit\n",
      " 11%|█▏        | 2501/22000 [04:05<29:43, 10.94it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5650699517.952, 'learning_rate': 1.772727272727273e-05, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 3002/22000 [04:51<29:34, 10.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5684314243.072, 'learning_rate': 1.7272727272727274e-05, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 3299/22000 [05:18<28:04, 11.10it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                    \n",
      " 15%|█▌        | 3300/22000 [05:25<28:04, 11.10it/s]Saving model checkpoint to regression_model\\checkpoint-3300\n",
      "Configuration saved in regression_model\\checkpoint-3300\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-3300\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5633213952.0, 'eval_runtime': 6.5185, 'eval_samples_per_second': 3614.047, 'eval_steps_per_second': 72.41, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-1100] due to args.save_total_limit\n",
      " 16%|█▌        | 3502/22000 [05:44<27:54, 11.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5633637089.28, 'learning_rate': 1.681818181818182e-05, 'epoch': 3.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 4002/22000 [06:30<26:45, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5675312742.4, 'learning_rate': 1.6363636363636366e-05, 'epoch': 3.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4400/22000 [07:07<23:51, 12.29it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                    \n",
      " 20%|██        | 4400/22000 [07:13<23:51, 12.29it/s]Saving model checkpoint to regression_model\\checkpoint-4400\n",
      "Configuration saved in regression_model\\checkpoint-4400\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-4400\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5632471040.0, 'eval_runtime': 6.6215, 'eval_samples_per_second': 3557.817, 'eval_steps_per_second': 71.283, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-2200] due to args.save_total_limit\n",
      " 20%|██        | 4501/22000 [07:24<30:10,  9.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5627192016.896, 'learning_rate': 1.590909090909091e-05, 'epoch': 4.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 5002/22000 [08:10<25:24, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5577851797.504, 'learning_rate': 1.5454545454545454e-05, 'epoch': 4.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5500/22000 [08:55<24:17, 11.32it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5691570388.992, 'learning_rate': 1.5000000000000002e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 25%|██▌       | 5500/22000 [09:02<24:17, 11.32it/s]Saving model checkpoint to regression_model\\checkpoint-5500\n",
      "Configuration saved in regression_model\\checkpoint-5500\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-5500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5631774720.0, 'eval_runtime': 6.4104, 'eval_samples_per_second': 3674.949, 'eval_steps_per_second': 73.63, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-3300] due to args.save_total_limit\n",
      " 27%|██▋       | 6002/22000 [09:48<24:10, 11.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5661118169.088, 'learning_rate': 1.4545454545454546e-05, 'epoch': 5.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 6501/22000 [10:34<23:05, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5645432520.704, 'learning_rate': 1.4090909090909092e-05, 'epoch': 5.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 6599/22000 [10:43<25:31, 10.06it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                    \n",
      " 30%|███       | 6600/22000 [10:50<25:31, 10.06it/s]Saving model checkpoint to regression_model\\checkpoint-6600\n",
      "Configuration saved in regression_model\\checkpoint-6600\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-6600\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5631122432.0, 'eval_runtime': 6.6055, 'eval_samples_per_second': 3566.436, 'eval_steps_per_second': 71.456, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-4400] due to args.save_total_limit\n",
      " 32%|███▏      | 7002/22000 [11:28<22:21, 11.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5632839122.944, 'learning_rate': 1.3636363636363637e-05, 'epoch': 6.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 7501/22000 [12:13<22:04, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5652276576.256, 'learning_rate': 1.3181818181818183e-05, 'epoch': 6.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7700/22000 [12:31<19:38, 12.13it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                    \n",
      " 35%|███▌      | 7700/22000 [12:38<19:38, 12.13it/s]Saving model checkpoint to regression_model\\checkpoint-7700\n",
      "Configuration saved in regression_model\\checkpoint-7700\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-7700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5630516224.0, 'eval_runtime': 6.6465, 'eval_samples_per_second': 3544.43, 'eval_steps_per_second': 71.015, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-5500] due to args.save_total_limit\n",
      " 36%|███▋      | 8002/22000 [13:06<20:52, 11.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5638991118.336, 'learning_rate': 1.2727272727272728e-05, 'epoch': 7.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 8502/22000 [13:52<20:19, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5692409249.792, 'learning_rate': 1.2272727272727274e-05, 'epoch': 7.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8800/22000 [14:19<18:20, 11.99it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                    \n",
      " 40%|████      | 8800/22000 [14:26<18:20, 11.99it/s]Saving model checkpoint to regression_model\\checkpoint-8800\n",
      "Configuration saved in regression_model\\checkpoint-8800\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-8800\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5629955072.0, 'eval_runtime': 6.6335, 'eval_samples_per_second': 3551.379, 'eval_steps_per_second': 71.154, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-6600] due to args.save_total_limit\n",
      " 41%|████      | 9002/22000 [14:46<19:52, 10.90it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5595514011.648, 'learning_rate': 1.181818181818182e-05, 'epoch': 8.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 9501/22000 [15:32<24:03,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5644206211.072, 'learning_rate': 1.1363636363636366e-05, 'epoch': 8.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9900/22000 [16:08<16:34, 12.17it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                    \n",
      " 45%|████▌     | 9900/22000 [16:15<16:34, 12.17it/s]Saving model checkpoint to regression_model\\checkpoint-9900\n",
      "Configuration saved in regression_model\\checkpoint-9900\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-9900\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5629438464.0, 'eval_runtime': 6.6455, 'eval_samples_per_second': 3544.964, 'eval_steps_per_second': 71.026, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-7700] due to args.save_total_limit\n",
      " 45%|████▌     | 10002/22000 [16:26<19:44, 10.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5649098866.688, 'learning_rate': 1.0909090909090909e-05, 'epoch': 9.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 10501/22000 [17:11<17:07, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5645474463.744, 'learning_rate': 1.0454545454545455e-05, 'epoch': 9.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 11000/22000 [17:57<16:07, 11.37it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5635704881.152, 'learning_rate': 1e-05, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 50%|█████     | 11000/22000 [18:04<16:07, 11.37it/s]Saving model checkpoint to regression_model\\checkpoint-11000\n",
      "Configuration saved in regression_model\\checkpoint-11000\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-11000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5628967424.0, 'eval_runtime': 6.6225, 'eval_samples_per_second': 3557.279, 'eval_steps_per_second': 71.272, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-8800] due to args.save_total_limit\n",
      " 52%|█████▏    | 11502/22000 [18:50<15:36, 11.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5661161160.704, 'learning_rate': 9.545454545454547e-06, 'epoch': 10.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 12001/22000 [19:37<15:10, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5638000738.304, 'learning_rate': 9.090909090909091e-06, 'epoch': 10.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 12100/22000 [19:47<14:59, 11.01it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                     \n",
      " 55%|█████▌    | 12100/22000 [19:53<14:59, 11.01it/s]Saving model checkpoint to regression_model\\checkpoint-12100\n",
      "Configuration saved in regression_model\\checkpoint-12100\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-12100\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5628541440.0, 'eval_runtime': 6.6375, 'eval_samples_per_second': 3549.238, 'eval_steps_per_second': 71.111, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-9900] due to args.save_total_limit\n",
      " 57%|█████▋    | 12502/22000 [20:31<14:15, 11.10it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5612533448.704, 'learning_rate': 8.636363636363637e-06, 'epoch': 11.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 13002/22000 [21:17<13:25, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5638982205.44, 'learning_rate': 8.181818181818183e-06, 'epoch': 11.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 13199/22000 [21:36<13:16, 11.05it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                     \n",
      " 60%|██████    | 13200/22000 [21:43<13:16, 11.05it/s]Saving model checkpoint to regression_model\\checkpoint-13200\n",
      "Configuration saved in regression_model\\checkpoint-13200\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-13200\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5628158976.0, 'eval_runtime': 6.6535, 'eval_samples_per_second': 3540.701, 'eval_steps_per_second': 70.94, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-11000] due to args.save_total_limit\n",
      " 61%|██████▏   | 13501/22000 [22:11<13:36, 10.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5643431837.696, 'learning_rate': 7.727272727272727e-06, 'epoch': 12.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 14001/22000 [22:57<12:05, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5658762018.816, 'learning_rate': 7.272727272727273e-06, 'epoch': 12.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 14299/22000 [23:25<11:16, 11.38it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                     \n",
      " 65%|██████▌   | 14300/22000 [23:32<11:16, 11.38it/s]Saving model checkpoint to regression_model\\checkpoint-14300\n",
      "Configuration saved in regression_model\\checkpoint-14300\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-14300\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5627823104.0, 'eval_runtime': 6.6325, 'eval_samples_per_second': 3551.914, 'eval_steps_per_second': 71.165, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-12100] due to args.save_total_limit\n",
      " 66%|██████▌   | 14502/22000 [23:52<11:05, 11.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5647842148.352, 'learning_rate': 6.818181818181818e-06, 'epoch': 13.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 15001/22000 [24:38<10:41, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5651499581.44, 'learning_rate': 6.363636363636364e-06, 'epoch': 13.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 15400/22000 [25:14<09:06, 12.08it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                     \n",
      " 70%|███████   | 15400/22000 [25:21<09:06, 12.08it/s]Saving model checkpoint to regression_model\\checkpoint-15400\n",
      "Configuration saved in regression_model\\checkpoint-15400\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-15400\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5627531776.0, 'eval_runtime': 6.6415, 'eval_samples_per_second': 3547.1, 'eval_steps_per_second': 71.068, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-13200] due to args.save_total_limit\n",
      " 70%|███████   | 15501/22000 [25:31<10:42, 10.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5631499567.104, 'learning_rate': 5.90909090909091e-06, 'epoch': 14.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 16001/22000 [26:18<09:24, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5621681750.016, 'learning_rate': 5.4545454545454545e-06, 'epoch': 14.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 16500/22000 [27:04<07:41, 11.93it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5660505800.704, 'learning_rate': 5e-06, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 75%|███████▌  | 16500/22000 [27:10<07:41, 11.93it/s]Saving model checkpoint to regression_model\\checkpoint-16500\n",
      "Configuration saved in regression_model\\checkpoint-16500\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-16500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5627284992.0, 'eval_runtime': 6.6005, 'eval_samples_per_second': 3569.138, 'eval_steps_per_second': 71.51, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-14300] due to args.save_total_limit\n",
      " 77%|███████▋  | 17002/22000 [27:57<07:36, 10.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5634190737.408, 'learning_rate': 4.5454545454545455e-06, 'epoch': 15.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 17501/22000 [28:43<06:55, 10.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5655182704.64, 'learning_rate': 4.0909090909090915e-06, 'epoch': 15.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 17599/22000 [28:53<07:00, 10.46it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                     \n",
      " 80%|████████  | 17600/22000 [29:00<07:00, 10.46it/s]Saving model checkpoint to regression_model\\checkpoint-17600\n",
      "Configuration saved in regression_model\\checkpoint-17600\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-17600\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5627083264.0, 'eval_runtime': 6.4804, 'eval_samples_per_second': 3635.244, 'eval_steps_per_second': 72.835, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-15400] due to args.save_total_limit\n",
      " 82%|████████▏ | 18001/22000 [29:37<06:12, 10.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5653773418.496, 'learning_rate': 3.6363636363636366e-06, 'epoch': 16.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 18502/22000 [30:22<05:14, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5607702134.784, 'learning_rate': 3.181818181818182e-06, 'epoch': 16.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 18699/22000 [30:41<04:53, 11.26it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                     \n",
      " 85%|████████▌ | 18700/22000 [30:48<04:53, 11.26it/s]Saving model checkpoint to regression_model\\checkpoint-18700\n",
      "Configuration saved in regression_model\\checkpoint-18700\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-18700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5626926592.0, 'eval_runtime': 6.6795, 'eval_samples_per_second': 3526.916, 'eval_steps_per_second': 70.664, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-16500] due to args.save_total_limit\n",
      " 86%|████████▋ | 19001/22000 [31:16<04:29, 11.15it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5646639431.68, 'learning_rate': 2.7272727272727272e-06, 'epoch': 17.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 19502/22000 [32:03<03:47, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5644858949.632, 'learning_rate': 2.2727272727272728e-06, 'epoch': 17.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 19800/22000 [32:30<03:03, 12.02it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                     \n",
      " 90%|█████████ | 19800/22000 [32:37<03:03, 12.02it/s]Saving model checkpoint to regression_model\\checkpoint-19800\n",
      "Configuration saved in regression_model\\checkpoint-19800\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-19800\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5626814464.0, 'eval_runtime': 6.6545, 'eval_samples_per_second': 3540.169, 'eval_steps_per_second': 70.93, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-17600] due to args.save_total_limit\n",
      " 91%|█████████ | 20002/22000 [32:56<03:13, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5646241497.088, 'learning_rate': 1.8181818181818183e-06, 'epoch': 18.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 20501/22000 [33:42<02:17, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5658376142.848, 'learning_rate': 1.3636363636363636e-06, 'epoch': 18.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 20900/22000 [34:19<01:32, 11.84it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n",
      "                                                     \n",
      " 95%|█████████▌| 20900/22000 [34:26<01:32, 11.84it/s]Saving model checkpoint to regression_model\\checkpoint-20900\n",
      "Configuration saved in regression_model\\checkpoint-20900\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-20900\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5626746880.0, 'eval_runtime': 6.7075, 'eval_samples_per_second': 3512.19, 'eval_steps_per_second': 70.369, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-18700] due to args.save_total_limit\n",
      " 95%|█████████▌| 21001/22000 [34:36<01:45,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5607116505.088, 'learning_rate': 9.090909090909091e-07, 'epoch': 19.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 21502/22000 [35:23<00:44, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5671963590.656, 'learning_rate': 4.5454545454545457e-07, 'epoch': 19.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22000/22000 [36:09<00:00, 11.09it/s]***** Running Evaluation *****\n",
      "  Num examples = 23558\n",
      "  Batch size = 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5631384748.032, 'learning_rate': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 22000/22000 [36:16<00:00, 11.09it/s]Saving model checkpoint to regression_model\\checkpoint-22000\n",
      "Configuration saved in regression_model\\checkpoint-22000\\config.json\n",
      "Model weights saved in regression_model\\checkpoint-22000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5626724352.0, 'eval_runtime': 6.5985, 'eval_samples_per_second': 3570.221, 'eval_steps_per_second': 71.532, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [regression_model\\checkpoint-19800] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from regression_model\\checkpoint-22000 (score: 5626724352.0).\n",
      "100%|██████████| 22000/22000 [36:16<00:00, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2176.764, 'train_samples_per_second': 1010.087, 'train_steps_per_second': 10.107, 'train_loss': 5644194700.567273, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=22000, training_loss=5644194700.567273, metrics={'train_runtime': 2176.764, 'train_samples_per_second': 1010.087, 'train_steps_per_second': 10.107, 'train_loss': 5644194700.567273, 'epoch': 20.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = RegressionTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"valid\"],\n",
    "    # compute_metrics=compute_metrics_for_regression,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file regression_model/checkpoint-20900/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"regression_model/checkpoint-20900/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"emb_size\": 312,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 312,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 600,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 3,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 29564\n",
      "}\n",
      "\n",
      "loading weights file regression_model/checkpoint-20900/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at regression_model/checkpoint-20900/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model_new = AutoModelForSequenceClassification.from_pretrained('regression_model/checkpoint-20900/', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.Tensor(ds['test'][0]['input_ids'])\n",
    "z = z.to(dtype=torch.int32, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000.000000000007"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[74.1521]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model(z)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([74.1521], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model(z)[0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['test'][0]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.cuda()\n",
    "model_new(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['test'].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "model_new.cuda()\n",
    "\n",
    "def prediction(dataset):\n",
    "    df = np.zeros((ds['test'].num_rows, 2))\n",
    "    for i, data in enumerate(tqdm(dataset)):\n",
    "        label = data['label']\n",
    "        data = data['input_ids']\n",
    "        data = torch.Tensor(data)\n",
    "        data = data.to(dtype=torch.int32, device='cuda')\n",
    "        label_hat = model_new(data)[0].detach().cpu().numpy()[0][0]\n",
    "\n",
    "        df[i, :] = [label_hat, label]\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "    return df\n",
    "\n",
    "array = prediction(ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x, x**2) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avito",
   "language": "python",
   "name": "avito"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7482cd81440b3a020188d9a10cc7e7c6bad69257b1d1766c51d3188cc75bb32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
